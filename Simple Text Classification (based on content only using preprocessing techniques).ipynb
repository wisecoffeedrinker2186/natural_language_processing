{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "94c0990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\atind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\atind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\atind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\atind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\atind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\atind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('treebank')\n",
    "from nltk.corpus import stopwords,treebank\n",
    "from nltk.stem import *\n",
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "56cd6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = '''\n",
    "Recent advances in medical research have brought hope to patients suffering from previously incurable diseases.\n",
    "With the advent of precision medicine, tailored treatments based on an individual's genetic makeup have shown promising results\n",
    "in cancer therapy. Additionally, breakthroughs in regenerative medicine are paving the way for organ transplantation without \n",
    "the need for immunosuppressants. These advancements are transforming the landscape of healthcare, offering new avenues for \n",
    "personalized and more effective treatments.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "54b3f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = '''\n",
    "The rapid evolution of technology continues to revolutionize our lives in remarkable ways. \n",
    "The rise of artificial intelligence and machine learning has enabled intelligent automation,\n",
    "streamlining processes across industries. In the field of robotics, innovations in soft robotics have shown great potential \n",
    "for human-robot interaction, making them safer and more adaptable. Furthermore, the advent of 5G technology promises to unlock\n",
    "unprecedented levels of connectivity,empowering the Internet of Things to thrive and ushering in a new era of seamless \n",
    "communication.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9558831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = '''\n",
    "Amid growing concerns about climate change, global efforts to combat environmental degradation have gained momentum.\n",
    "Renewable energy sources, such as solar and wind power, are witnessing widespread adoption, gradually reducing our dependence \n",
    "on fossil fuels and mitigating greenhouse gas emissions. Sustainable practices, like eco-friendly packaging and circular \n",
    "economy initiatives, are gaining traction in businesses, emphasizing the importance of responsible consumption. As conservation\n",
    "and biodiversity preservation become imperative, collective action and awareness continue to shape a more sustainable future \n",
    "for our planet.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb12dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 'this is a sentence to ,...clean clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f3aabcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = [',','.','!','...','\\'s']\n",
    "words = nltk.word_tokenize(text1.lower()) # change here to try\n",
    "words = [word for word in words if word not in punctuations]\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0c24dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('english'))\n",
    "stop_words.extend(['without','have','new','way'])\n",
    "clean_words = [word for word in words if word not in stop_words]\n",
    "# clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "898a40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = WordNetLemmatizer()\n",
    "lemmed_words = [lemmer.lemmatize(word) for word in clean_words]\n",
    "# lemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a7fc3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "# stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83c42d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recent': 1,\n",
       " 'advance': 1,\n",
       " 'medical': 1,\n",
       " 'research': 1,\n",
       " 'brought': 1,\n",
       " 'hope': 1,\n",
       " 'patient': 1,\n",
       " 'suffering': 1,\n",
       " 'previously': 1,\n",
       " 'incurable': 1,\n",
       " 'disease': 1,\n",
       " 'advent': 1,\n",
       " 'precision': 1,\n",
       " 'medicine': 2,\n",
       " 'tailored': 1,\n",
       " 'treatment': 2,\n",
       " 'based': 1,\n",
       " 'individual': 1,\n",
       " 'genetic': 1,\n",
       " 'makeup': 1,\n",
       " 'shown': 1,\n",
       " 'promising': 1,\n",
       " 'result': 1,\n",
       " 'cancer': 1,\n",
       " 'therapy': 1,\n",
       " 'additionally': 1,\n",
       " 'breakthrough': 1,\n",
       " 'regenerative': 1,\n",
       " 'paving': 1,\n",
       " 'organ': 1,\n",
       " 'transplantation': 1,\n",
       " 'need': 1,\n",
       " 'immunosuppressant': 1,\n",
       " 'advancement': 1,\n",
       " 'transforming': 1,\n",
       " 'landscape': 1,\n",
       " 'healthcare': 1,\n",
       " 'offering': 1,\n",
       " 'avenue': 1,\n",
       " 'personalized': 1,\n",
       " 'effective': 1}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = dict()\n",
    "for i  in lemmed_words:\n",
    "    if i in word_freq.keys():\n",
    "        word_freq[i] += 1\n",
    "    else:\n",
    "        word_freq[i] = 1\n",
    "# word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60d48054",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-1d68d12af884>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_freq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword_freq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "word_freq = sorted(word_freq.items(), key=lambda item: (item[1],item[0]),reverse=True)\n",
    "# word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f8dee082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('treatment', 2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = word_freq[0]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "10308ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = {\n",
    "#     \"Medical text\":\n",
    "#     ['medical', 'medicine', 'disease', 'treatment', 'healthcare'],\n",
    "#     \"Technological text\": ['technology','robotics','internet'],\n",
    "#     \"Ecological text\": ['sustainable','renewable','solar','environmental','conservation'],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea7ddd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydict = {'george': 16, 'amber': 19}\n",
    "# print mydict.keys()[mydict.values().index(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e73cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in labels.values():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "426fe455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    #lowercase and cleaning puncuations \n",
    "    words = nltk.word_tokenize(text.lower()) #passing text \n",
    "    words = [word for word in words if word not in punctuations]\n",
    "    \n",
    "    #stop-word removal\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    stop_words.extend(['without','have','new','way'])\n",
    "    clean_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    #lemmatiztion \n",
    "    lemmer = WordNetLemmatizer()\n",
    "    lemmed_words = [lemmer.lemmatize(word) for word in clean_words]\n",
    "    \n",
    "    #word-freq counter\n",
    "    word_freq = dict()\n",
    "    for i  in lemmed_words:\n",
    "        if i in word_freq.keys():\n",
    "            word_freq[i] += 1\n",
    "        else:\n",
    "            word_freq[i] = 1\n",
    "    word_freq = sorted(word_freq.items(), key=lambda item: (item[1],item[0]),reverse=True)\n",
    "\n",
    "    return word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6df4cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text_preprocessing(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d0847977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text,high_freq_word_count=3):\n",
    "    labels = {\n",
    "        \"Medical text\":\n",
    "        ['medical', 'medicine', 'disease', 'treatment', 'healthcare'],\n",
    "        \"Technological text\": ['technology', 'robotics', 'internet'],\n",
    "        \"Ecological text\":\n",
    "        ['sustainable', 'renewable', 'climate', 'environmental', 'conservation'],\n",
    "    }\n",
    "    \n",
    "    freq_list = text_preprocessing(text)\n",
    "    high_freq_words = [i[0] for i in freq_list[:high_freq_word_count]]\n",
    "    \n",
    "    flag = False\n",
    "    for i in labels.values():\n",
    "        if bool(set(high_freq_words).intersection(i)):\n",
    "            result = list(labels.keys())[list(labels.values()).index(i)]\n",
    "            flag = True\n",
    "            \n",
    "            \n",
    "    if not flag:\n",
    "        return \"Text cannot be classified with current model\"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "defcd044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technological text'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9b53df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [text1,text2,text3] are the three availabe texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
